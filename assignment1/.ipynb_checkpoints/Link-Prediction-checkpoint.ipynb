{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nw\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nw.Graph()\n",
    "nodes = []\n",
    "\n",
    "# input 'train.txt'\n",
    "with open('train.txt') as file:\n",
    "    for line in file:\n",
    "        token = line.split()\n",
    "        source = token[0]\n",
    "        sinks = token[1:]\n",
    "        \n",
    "        #generate network graph\n",
    "        if source not in graph.nodes:\n",
    "            graph.add_node(source)\n",
    "            \n",
    "        for sink in sinks:\n",
    "            if sink not in graph.nodes:\n",
    "                graph.add_node(sink)\n",
    "            \n",
    "            graph.add_edge(source, sink)\n",
    "            nodes.append((source,sink))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 'nodes.json'\n",
    "with open('nodes.json') as file:\n",
    "    json_file = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value of \"first\" key for every node\n",
    "first_list = []\n",
    "for obj in json_file:\n",
    "    for k, v in obj.items():\n",
    "        if k == \"first\":\n",
    "            first_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value of \"last\" key for every node\n",
    "last_list = []\n",
    "for obj in json_file:\n",
    "    for k, v in obj.items():\n",
    "        if k == \"last\":\n",
    "            last_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value of \"num_papers\" key for every node\n",
    "num_papers_list = []\n",
    "for obj in json_file:\n",
    "    for k, v in obj.items():\n",
    "        if k == \"num_papers\":\n",
    "            num_papers_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 16, 6, 24, 145]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_papers_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get every key which contian \"keyword\" for each node (e.g. \"keyword_0\", \"keyword_1\")\n",
    "keyword_list = []\n",
    "for e in json_file:\n",
    "    keys = []\n",
    "    for k in e:\n",
    "        key = re.findall(r'keyword_[0-9]*', k)\n",
    "        keys.append(key)\n",
    "        \n",
    "    new_keys=[x for x in keys if x]\n",
    "    keyword_list.append(new_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get every key which contian \"venue\" for each node (e.g. \"venue_0\", \"venue_1\")\n",
    "venue_list = []\n",
    "for e in json_file:\n",
    "    venues = []\n",
    "    for v in e:\n",
    "        venue = re.findall(r'venue_[0-9]*', v)\n",
    "        venues.append(venue)\n",
    "        \n",
    "    new_venues=[x for x in venues if x]\n",
    "    venue_list.append(new_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_edges = list(graph.edges)\n",
    "test_positive_edges = []\n",
    "\n",
    "connected_part_num = nw.number_connected_components(graph)\n",
    "temp_graph = graph.copy()\n",
    "test_positive_num = int(len(graph.edges) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide positive edges into training set and testing set\n",
    "while len(test_positive_edges) <= test_positive_num:\n",
    "    a1, a2 = random.sample(train_positive_edges, 1)[0]\n",
    "    \n",
    "    temp_graph.remove_edge(a1,a2)\n",
    "    if nw.number_connected_components(temp_graph) != connected_part_num:\n",
    "        temp_graph.add_edge(a1, a2)\n",
    "        continue\n",
    "    \n",
    "    test_positive_edges.append((a1, a2))\n",
    "    train_positive_edges.remove((a1, a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nagetive_edges = []\n",
    "nagetive_edge_num = len(graph.edges)\n",
    "all_nodes = list(graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate nagetive edges\n",
    "while len(nagetive_edges) < nagetive_edge_num:\n",
    "    node1 = random.sample(all_nodes, 1)[0]\n",
    "    node2 = random.sample(all_nodes, 1)[0]\n",
    "    \n",
    "    if (node1 == node2 or\n",
    "        (node1, node2) in graph.edges or\n",
    "        (node2, node1) in graph.edges or\n",
    "        (node1, node2) in nagetive_edges or\n",
    "        (node2, node1) in nagetive_edges):\n",
    "        continue\n",
    "    \n",
    "    nagetive_edges.append((node1, node2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide nagetive edges into training set and testing set\n",
    "test_nagetive_num = int(len(graph.edges) * 0.8)\n",
    "train_nagetive_edges = nagetive_edges[:test_nagetive_num]\n",
    "test_nagetive_edges = nagetive_edges[test_nagetive_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(node, graph):\n",
    "    if node in graph.nodes:\n",
    "        return graph.adj[node]\n",
    "    else:\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neighbours(node1, node2, graph):\n",
    "    neighbours1 = get_neighbours(node1, graph)\n",
    "    neighbours2 = get_neighbours(node2, graph)\n",
    "    \n",
    "    ans = len(neighbours1) + len(neighbours2)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferential Attachment\n",
    "def pa(node1, node2, graph):\n",
    "    neighbours1 = get_neighbours(node1, graph)\n",
    "    neighbours2 = get_neighbours(node2, graph)\n",
    "    \n",
    "    ans = len(neighbours1) * len(neighbours2)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbour_num(node1, node2, graph):\n",
    "    neighbours1 = get_neighbours(node1, graph)\n",
    "    neighbours2 = get_neighbours(node2, graph)\n",
    "    \n",
    "    commmon_neighbours = set(neighbours1).intersection(set(neighbours2))\n",
    "\n",
    "    return len(commmon_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_keyword_num(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    common_kcount = 0\n",
    "\n",
    "    for i in keyword_list[n1]:\n",
    "        if i in keyword_list[n2]:\n",
    "            common_kcount = common_kcount + 1\n",
    "\n",
    "    return common_kcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_venue_num(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    common_vcount = 0\n",
    "\n",
    "    for i in venue_list[n1]:\n",
    "        if i in venue_list[n2]:\n",
    "            common_vcount = common_vcount + 1\n",
    "\n",
    "    return common_vcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_neighbour_num(node1, node2, graph):\n",
    "    neighbours1 = get_neighbours(node1, graph)\n",
    "    neighbours2 = get_neighbours(node2, graph)\n",
    "    \n",
    "    union_neighbour = set(neighbours1).union(set(neighbours2))\n",
    "    return len(union_neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_keyword_num(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    union_klist = keyword_list[n2].copy()\n",
    "\n",
    "    for i in keyword_list[n1]:\n",
    "        if i not in keyword_list[n2]:\n",
    "            union_klist.append(i)\n",
    "\n",
    "    return len(union_klist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_venue_num(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    union_vlist = venue_list[n2].copy()\n",
    "\n",
    "    for i in venue_list[n1]:\n",
    "        if i not in venue_list[n2]:\n",
    "            union_vlist.append(i)\n",
    "\n",
    "    return len(union_vlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(node1, node2, graph):\n",
    "    common_neighbours_num = common_neighbour_num(node1, node2, graph)\n",
    "    union_neighbours_num = union_neighbour_num(node1, node2, graph)\n",
    "    \n",
    "    return common_neighbours_num / union_neighbours_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_keyword(node1, node2, graph):\n",
    "    k_ans = common_keyword_num(node1, node2, graph) / union_keyword_num(node1, node2, graph)\n",
    "    return k_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_venue(node1, node2, graph):\n",
    "    v_ans = common_venue_num(node1, node2, graph) / union_venue_num(node1, node2, graph)\n",
    "    return v_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar(node1, node2, graph):\n",
    "    neighbours1 = get_neighbours(node1, graph)\n",
    "    neighbours2 = get_neighbours(node2, graph)\n",
    "    \n",
    "    commmon_neighbours = set(neighbours1).intersection(set(neighbours2))\n",
    "    \n",
    "    ans = 0\n",
    "    for node in commmon_neighbours:\n",
    "        neighbours3 = get_neighbours(node, graph)\n",
    "        neighbours3_num = len(neighbours3)\n",
    "        ans += 1 / math.log(neighbours3_num)\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ra(node1, node2, graph):\n",
    "    neighbours1 = get_neighbours(node1, graph)\n",
    "    neighbours2 = get_neighbours(node2, graph)\n",
    "    \n",
    "    commmon_neighbours = set(neighbours1).intersection(set(neighbours2))\n",
    "    \n",
    "    ans = 0\n",
    "    for node in commmon_neighbours:\n",
    "        neighbours3 = get_neighbours(node, graph)\n",
    "        neighbours3_num = len(neighbours3)\n",
    "        ans += 1 / neighbours3_num\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_difference(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    t1 = abs(first_list[n1] - last_list[n1])\n",
    "    t2 = abs(first_list[n2] - last_list[n2])\n",
    "    ans = abs(t1 - t2)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_time(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    t1 = abs(first_list[n1] - last_list[n1])\n",
    "    t2 = abs(first_list[n2] - last_list[n2])\n",
    "    time = max(first_list[n1], first_list[n2]) - min(last_list[n1], last_list[n2])\n",
    "    \n",
    "    ans = t1 + t2 - time\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_difference(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    ans = abs(last_list[n1] - last_list[n2])\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_sum(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    ans = num_papers_list[n1] + num_papers_list[n2]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kw_cos_similarity(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    kcount = common_keyword_num(node1, node2, graph)\n",
    "    kn1 = len(keyword_list[n1])\n",
    "    kn2 = len(keyword_list[n2])\n",
    "    sqrt = math.sqrt(kn1) *  math.sqrt(kn2)\n",
    "    \n",
    "    if sqrt == 0:\n",
    "        cos = 0\n",
    "    else:\n",
    "        cos = kcount / sqrt\n",
    "    \n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def venue_cos_similarity(node1, node2, graph):\n",
    "    n1 = int(node1)\n",
    "    n2 = int(node2)\n",
    "    vcount = common_venue_num(node1, node2, graph)\n",
    "    vn1 = len(venue_list[n1])\n",
    "    vn2 = len(venue_list[n2])\n",
    "    sqrt = math.sqrt(vn1) *  math.sqrt(vn2)\n",
    "    \n",
    "    if sqrt == 0:\n",
    "        cos = 0\n",
    "    else:\n",
    "        cos = vcount / sqrt\n",
    "    \n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(edge):\n",
    "    vectorize = []\n",
    "    \n",
    "    node1, node2 = edge\n",
    "    feature1 = common_neighbour_num(node1, node2, temp_graph)\n",
    "    # feature2 = union_neighbour_num(node1, node2, temp_graph)\n",
    "    feature3 = jaccard(node1, node2, temp_graph)\n",
    "    feature4 = adamic_adar(node1, node2, temp_graph)\n",
    "    # feature5 = jaccard_detail(node1, node2, temp_graph)\n",
    "    # feature6 = common_keyword_num(node1, node2, temp_graph)\n",
    "    # feature7 = common_venue_num(node1, node2, temp_graph)\n",
    "    # feature8 = jaccard_keyword(node1, node2, temp_graph)\n",
    "    feature9 = jaccard_venue(node1, node2, temp_graph)\n",
    "    # feature10 = union_keyword_num(node1, node2, temp_graph)\n",
    "    # feature11 = union_venue_num(node1, node2, temp_graph)\n",
    "    feature12 = pa(node1, node2, temp_graph)\n",
    "    feature13 = ra(node1, node2, temp_graph)\n",
    "    # feature14 = add_neighbours(node1, node2, temp_graph)\n",
    "    # feature15 = paper_sum(node1, node2, temp_graph)\n",
    "    feature16 = time_difference(node1, node2, temp_graph)\n",
    "    feature17 = last_time_difference(node1, node2, temp_graph)\n",
    "    feature18 = kw_cos_similarity(node1, node2, temp_graph)\n",
    "    feature19 = venue_cos_similarity(node1, node2, temp_graph)\n",
    "    feature20 = overlap_time(node1, node2, temp_graph)\n",
    "    \n",
    "    return np.array([feature1, feature3, feature4, feature8, feature9, feature12, feature13, feature17, feature18, feature19, feature20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add label\n",
    "train_matrix = []\n",
    "train_label = [1] * len(train_positive_edges) + [0] * len(train_nagetive_edges)\n",
    "test_matrix = []\n",
    "test_label = [1] * len(test_positive_edges) + [0] * len(test_nagetive_edges)\n",
    "\n",
    "for edge in train_positive_edges + train_nagetive_edges:\n",
    "    train_matrix.append(vectorize(edge))\n",
    "    \n",
    "for edge in test_positive_edges + test_nagetive_edges:\n",
    "    test_matrix.append(vectorize(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = np.vstack(train_matrix)\n",
    "train_label = np.array(train_label)\n",
    "test_matrix = np.vstack(test_matrix)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle training dataset\n",
    "index = list(range(len(train_matrix)))\n",
    "random.shuffle(index)\n",
    "\n",
    "new_train_matrix = train_matrix[np.array(index)]\n",
    "new_train_label = train_label[np.array(index)]\n",
    "\n",
    "#shuffle testing dataset\n",
    "index2 = list(range(len(test_matrix)))\n",
    "random.shuffle(index2)\n",
    "\n",
    "new_test_matrix = test_matrix[np.array(index2)]\n",
    "new_test_label = test_label[np.array(index2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=8, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(max_depth = 8)\n",
    "classifier.fit(new_train_matrix, new_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9476614699331849"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_on_test = classifier.score(new_test_matrix, new_test_label)\n",
    "score_on_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.41896999e-03, 9.92581030e-01],\n",
       "       [9.30851266e-01, 6.91487338e-02],\n",
       "       [7.71616450e-01, 2.28383550e-01],\n",
       "       [1.73060234e-02, 9.82693977e-01],\n",
       "       [8.27588743e-04, 9.99172411e-01]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_on_my_testset = classifier.predict_proba(new_test_matrix)\n",
    "probs_on_my_testset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public_edges = []\n",
    "indexes = []\n",
    "with open('test-public.csv') as test_file:\n",
    "    for line in test_file:\n",
    "        if line.startswith('Id'):\n",
    "            continue\n",
    "        splited = line.strip().split(',')\n",
    "        indexes.append(splited[0])\n",
    "        test_public_edges.append((splited[1], splited[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public_matrix = []\n",
    "for edge in test_public_edges:\n",
    "    test_public_matrix.append(vectorize(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public_matrix = np.vstack(test_public_matrix)\n",
    "\n",
    "test_public_proba = classifier.predict_proba(test_public_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93100074, 0.06899926],\n",
       "       [0.78134408, 0.21865592],\n",
       "       [0.95509211, 0.04490789],\n",
       "       [0.03855286, 0.96144714],\n",
       "       [0.26652158, 0.73347842]])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_public_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(proba, file):\n",
    "    with open(file, 'w') as test_file:\n",
    "        test_file.write('Id,Predicted\\n')\n",
    "        for index, prob in zip(indexes, test_public_proba):\n",
    "            test_file.write(\"{},{}\\n\".format(index, prob[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission_file(test_public_proba, 'submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
